 ---
layout: post
title: Don't Dumb It Down
author: Romulus10
---
While talking to my less technically-interested friends I've noticed more and more that it is a common belief among this extraordinarily digital generation that the tools that they use every day are simply too advanced for them to understand. Just today I was telling a few friends about the work I was doing on this website and was immediately told to 'dumb it down' for them. I absolutely understand that there are words and phrases and concepts that are particular to computing that other fields don't use because they honestly just don't have any need for them. But being told to dumb it down got me thinking- and I think that the belief that computing is 'too complicated' for anyone to understand is just untrue.   
Notice in the opening that I referred to my friends as 'less technically-interested' rather than 'less technically-inclined.' Sure, some people might tend to have more aptitude with computing than others. However nobody is incapable of understanding. High schools straight on down to grade schools spend so much time memorizing and regurgitating things for standardized examinations, we're used to very cut-and-dry, fact- and memory-based study. Application tends to be placed outside the realm of what is considered relevant until college age. 
Most people tend to be far more comfortable with taking a biology or chemistry class than they are with taking a computing science class. Each of these fields have their own arcane jargon and applications that branch off into hundreds of subsidiary fields. Why, then, are we requiring some and not the others? The fact seems to be that people  have this image (perpetuated by the media for years) of someone who spends hours of their lives locked away from human interaction mastering strange and confusing skills that allow them to get into your computer and steal your personal information. Just recently I saw a television commercial that featured the 'hacker' deviously sitting at a laptop in a dimly-lit room gleefully pressing buttons. Most people look over my shoulder at the masses of code I write and inform me that they could simply never do it. 
But wait.   
Who's stopping you?     
Maybe it's not a skill that you'll need for your life. Most people probably won't be writing software for a living. A good portion of the population won't need to code or fix a computer by hand; people study for years to learn how to do these things for them. However, having a basic grasp of how it works can be an incredibly valuable skill. Consider this blog post- I'm clearly not a writer. I don't have an extensive background in writing things like articles or blog posts, I'm hardly going to be doing it for a living, but here you are reading my post. Having a decent understanding of how to manipulate the English language is a skill that is widespread. My point is that understanding and manipulating the language(s) of the computing world can be just as helpful. While working a minimum wage customer service job which had absolutely nothing to do with coding and which required me to quickly and accurately check and compare large volumes of financial information, I noticed that I was tending to carry out the same set of very repetitive tasks, mostly simple math. I found that the number of oversights and general errors was decreased drastically by automation. I worked out the exact algorithm I was following, and condensed it into a program I could run through an app on my phone. It's nothing intensive, it's only about twenty lines of Python for you other coders in the audience. It's the most basic programming instructions written to process simple arithmetic.     
Even if you're just learning to record simple macros in Microsoft Office or programming your calculator to do financial calculations for you, an understanding of computing can be useful for automation. There are simple computer problems that can be fixed in minutes without a call to tech support. A basic understanding can help to tell you why that button isn't a good one to click on. Anybody can get the resources. We just need to start making them available. If we start integrating now, our next generation will be able to handle the tools we pass on to them that much better. We can create whole new areas of skilled work we never even imagined. These are just my personal thoughts on the matter. I might be a bit biased, but I strongly believe that by integrating an understanding of computing into our social consciousness we can begin to remove the barriers surrounding the computing workforce and begin to change the way we do things in unprecedented ways. Let's keep the world on the path to learning how to build and develop and expand and help. One code monkey might not be an answer to world hunger, but it takes a lot of different people to make the world a better place. Who knows what kind of people might tackle the worlds issues in the years to come? So when you're talking about your passions, don't dumb it down. You might wake up new curiosity in somebody who never knew it was there. 